{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4406dd8-76a5-45c3-a2d6-d4b608fa4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d83faef6-024b-4797-bf21-08d5ee63ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_movies = pd.read_csv(\"E:/Data Scientist/8. Regular Expression in Python/short_movies.csv\")\n",
    "wikipedia = pd.read_csv(\"E:/Data Scientist/8. Regular Expression in Python/wikipedia.csv\")\n",
    "tweets = pd.read_csv(\"E:/Data Scientist/8. Regular Expression in Python/short_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e121f1e-379d-4a7e-8811-030c3a28d47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>html</th>\n",
       "      <th>sent id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    tag   html  sent id  \\\n",
       "0   0  cv000  29590        0   \n",
       "1   0  cv000  29590        1   \n",
       "2   0  cv000  29590        2   \n",
       "3   0  cv000  29590        3   \n",
       "4   0  cv000  29590        4   \n",
       "\n",
       "                                                text target  \n",
       "0  films adapted from comic books have had plenty...    pos  \n",
       "1  for starters , it was created by alan moore ( ...    pos  \n",
       "2  to say moore and campbell thoroughly researche...    pos  \n",
       "3  the book ( or \" graphic novel , \" if you will ...    pos  \n",
       "4  in other words , don't dismiss this film becau...    pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5d055e-61c0-4541-98ec-c5e84e3c0f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$i supposed that coming from mtv films i should expect no less$\n"
     ]
    }
   ],
   "source": [
    "movie = \"$I supposed that coming from MTV Films I should expect no less$\"\n",
    "\n",
    "movie_lower = movie.lower()\n",
    "print(movie_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a307746-9899-4a99-bc01-78bd1703073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i supposed that coming from mtv films i should expect no less\n"
     ]
    }
   ],
   "source": [
    "# Remove specified character and print the result\n",
    "movie_no_sign = movie_lower.strip('$')\n",
    "print(movie_no_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21bb42de-e081-4ea9-ae49-f6e66d51c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'supposed', 'that', 'coming', 'from', 'mtv', 'films', 'i', 'should', 'expect', 'no', 'less']\n"
     ]
    }
   ],
   "source": [
    "# Split the string into substrings and print the result\n",
    "movie_split = movie_no_sign.split()\n",
    "print(movie_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "675dd7c4-223a-4587-ac33-bd25c6c15286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n"
     ]
    }
   ],
   "source": [
    "word_root = movie_split[1][1]\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c1594fb-c7d6-4958-9ad3-1eafb2b650b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film,however,is all good\n"
     ]
    }
   ],
   "source": [
    "movie = \"the film,however,is all good<\\i>\"\n",
    "\n",
    "# Remove tags happening at the end and print results\n",
    "movie_tag = movie.rstrip('<\\i>')\n",
    "print(movie_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98632429-67a3-4d9e-9b24-c2e8ccf478b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the film', 'however', 'is all good']\n"
     ]
    }
   ],
   "source": [
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(',')\n",
    "print(movie_no_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92209896-8b1a-41c4-8863-78fb3c9747d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film however is all good\n"
     ]
    }
   ],
   "source": [
    "# Join back together and print results\n",
    "movie_join = ' '.join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f17a56-12e5-47fb-8934-70f14cf05ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"mtv films election, a high school comedy, is a current example from there, director steven spielberg wastes no time, taking us into the water on a midnight swim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708721d4-96ff-4bae-9c76-7daaecb00e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mtv films election, a high school comedy, is a current example from there, director steven spielberg wastes no time, taking us into the water on a midnight swim']\n",
      "['mtv films election', ' a high school comedy', ' is a current example from there', ' director steven spielberg wastes no time', ' taking us into the water on a midnight swim']\n"
     ]
    }
   ],
   "source": [
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(',')\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d61fd9d-fd60-4cff-b649-42c817dbbf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tool</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Natural Language Toolkit</td>\n",
       "      <td>suite of libraries and programs for symbolic a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TextBlob</td>\n",
       "      <td>Python library for processing textual data. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gensim</td>\n",
       "      <td>Gensim is a robust open-source vector space mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>In computer science, artificial intelligence (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      tool  \\\n",
       "0           0  Natural Language Toolkit   \n",
       "1           1                  TextBlob   \n",
       "2           2                    Gensim   \n",
       "3           3   artificial intelligence   \n",
       "\n",
       "                                         description  \n",
       "0  suite of libraries and programs for symbolic a...  \n",
       "1  Python library for processing textual data. It...  \n",
       "2  Gensim is a robust open-source vector space mo...  \n",
       "3  In computer science, artificial intelligence (...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6de20fa-ecf8-4f6a-99b5-f383003b460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_article = \"In computer science, artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49ed70bc-fc09-45e3-90ea-06e57e647943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = wikipedia_article[3:19].lower()\n",
    "second_pos = wikipedia_article[21:44].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fbb07c7-3067-4c06-b314-5e5e1172ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = []\n",
    "\n",
    "my_list.append(\"The tool {} is used in {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df1b34d7-0036-4a23-a05f-ece03b1d4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"The tool {1} is used in {0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02af1970-7be5-414b-b541-678c13ae36ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tool computer science is used in artificial intelligence\n",
      "The tool artificial intelligence is used in computer science\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use format to print strings\n",
    "for my_string in my_list:\n",
    "  \tprint(my_string.format(first_pos, second_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc3904a8-5607-448e-9962-ef94b0acc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = ['artificial intelligence', 'neural networks']\n",
    "\n",
    "# Create a dictionary\n",
    "plan = {\n",
    "  \t\t\"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "577e3f22-06f3-46ed-9fd5-ac319566f7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in artificial intelligence, you can take the course related to neural networks\n"
     ]
    }
   ],
   "source": [
    "# Complete the placeholders accessing elements of field and tool keys in the data dictionary\n",
    "my_message = \"If you are interested in {data[field]}, you can take the course related to {data[tool]}\"\n",
    "\n",
    "# Use the plan dictionary to replace placeholders\n",
    "print(my_message.format(data=plan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc1799b6-4f36-46b0-89c3-a505b73e8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is October 20, 2024. It's 18:53 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Import datetime \n",
    "from datetime import datetime\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()\n",
    "\n",
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Use the format method replacing the placeholder with get_date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0e24d4-3ebf-4725-aed0-ee5ec6871edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f912eacf-abb5-4eea-9477-61c0708ab485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot9!', '@robot4&', '@robot9$', '@robot7%']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = \"@robot9! @robot4& I have a good feeling that the show isgoing to be amazing! @robot9$ @robot7%\"\n",
    "\n",
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fe3e685-15ca-4767-8e0c-3d75b19d3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User_mentions:2']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = \"Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\"\n",
    "\n",
    "# Write a regex to obtain user mentions\n",
    "print(re.findall(r\"User_mentions:\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c04f23dc-4588-4e12-b0d0-34a3c68ac5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['likes: 9']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of likes\n",
    "print(re.findall(r\"likes:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a99baa32-9523-4650-bb5b-bbab9656d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number of retweets: 7']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to obtain number of retweets\n",
    "print(re.findall(r\"number\\sof\\sretweets:\\s\\d\", sentiment_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22234659-91b6-4e65-b955-6c0937f45b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately one of those moments wasn't a giant squid monster. User_mentions:2, likes: 9, number of retweets: 7\n"
     ]
    }
   ],
   "source": [
    "# Write a regex to match pattern separating sentences\n",
    "regex_sentence = r\"\\W\\dbreak\\W\"\n",
    "\n",
    "# Replace the regex_sentence with a space\n",
    "sentiment_sub = re.sub(regex_sentence, \" \", sentiment_analysis)\n",
    "\n",
    "# Write a regex to match pattern separating words\n",
    "regex_words = r\"\\Wnew\\w\"\n",
    "\n",
    "# Replace the regex_words and print the result\n",
    "sentiment_final = re.sub(regex_words, \" \", sentiment_sub)\n",
    "print(sentiment_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cba310c-8ff8-465d-9060-4615812f64a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467821085</td>\n",
       "      <td>Mon Apr 06 22:22:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>crzy_cdn_bulas</td>\n",
       "      <td>our duck and chicken are taking wayyy too long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467821338</td>\n",
       "      <td>Mon Apr 06 22:22:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>justnetgirl</td>\n",
       "      <td>Put vacation photos online (They were so cute)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467821455</td>\n",
       "      <td>Mon Apr 06 22:22:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CiaraRenee</td>\n",
       "      <td>I need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467821715</td>\n",
       "      <td>Mon Apr 06 22:22:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>deelau</td>\n",
       "      <td>@andywana Not sure what they are, only that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467822384</td>\n",
       "      <td>Mon Apr 06 22:22:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Lindsey0920</td>\n",
       "      <td>@oanhLove I hate when that happens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag            user  \\\n",
       "0       0  1467821085  Mon Apr 06 22:22:26 PDT 2009  NO_QUERY  crzy_cdn_bulas   \n",
       "1       0  1467821338  Mon Apr 06 22:22:30 PDT 2009  NO_QUERY     justnetgirl   \n",
       "2       0  1467821455  Mon Apr 06 22:22:32 PDT 2009  NO_QUERY      CiaraRenee   \n",
       "3       0  1467821715  Mon Apr 06 22:22:37 PDT 2009  NO_QUERY          deelau   \n",
       "4       0  1467822384  Mon Apr 06 22:22:47 PDT 2009  NO_QUERY     Lindsey0920   \n",
       "\n",
       "                                                text  \n",
       "0  our duck and chicken are taking wayyy too long...  \n",
       "1  Put vacation photos online (They were so cute)...  \n",
       "2                                      I need a hug   \n",
       "3  @andywana Not sure what they are, only that th...  \n",
       "4             @oanhLove I hate when that happens...   "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a376fc8-8e3d-480c-9e57-86518f13e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545       jess___x\n",
      "546         Zimily\n",
      "547    Augustina22\n",
      "Name: user, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = tweets.iloc[545:548, 4]\n",
    "print(sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5e8df09-26e3-4301-b73a-f99a7d99dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"http\\S+\", tweet))\n",
    "\n",
    "\t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e4c18c0-b87c-4566-8cbe-f05dd6879b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITS', 'NOT', 'ENOUGH', 'TO', 'SAY', 'THAT', 'IMISS', 'U', '']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = \"ITS NOT ENOUGH TO SAY THAT IMISS U #MissYou #SoMuch #Friendship #Forever\"\n",
    "\n",
    "# Write a regex matching the hashtag pattern\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex, \"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45ddcf-47e1-4763-ae34-4394222499c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
